version: '3'
services:
  postgres:
    image: postgres:14
    environment:
      - POSTGRES_DB=db
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=airflow
    volumes:
      - ./database/:/var/lib/postgresql/data
    ports:
      - "5436:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-d", "db", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  scheduler:
    build: .
    command: poetry run airflow scheduler
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:${POSTGRES_PASSWORD}@postgres:5432/db
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - LAKE_BUCKET=${LAKE_BUCKET}
      - GOOGLE_APPLICATION_CREDENTIALS=${GOOGLE_APPLICATION_CREDENTIALS}
      - BRONZE_DATA_SET_NAME=${BRONZE_DATA_SET_NAME}
      - PROJECT_ID=${PROJECT_ID}
      - GCLOUD_KEY_PATH={$GCLOUD_KEY_PATH}
    volumes:
      - ./dags:/app/airflow/dags
      - ./logs:/app/airflow/logs
      - ./data:/app/airflow/data
      - ${GCLOUD_KEY_PATH}:${GOOGLE_APPLICATION_CREDENTIALS}
    depends_on:
      - postgres
    restart: on-failure

  webserver:
    build: .
    command: poetry run scripts/entrypoint.sh
    environment:
      - POSTGRES_DB=db
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=airflow
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:${POSTGRES_PASSWORD}@postgres:5432/db
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    volumes:
      - ./dags:/app/airflow/dags
      - ./logs:/app/airflow/logs
      - ./data:/app/airflow/data
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - scheduler
    restart: on-failure
    healthcheck:
      test: ["CMD", "-f", "/home/airflow/airflow-webserver.pid"]
      interval: 30s
      timeout: 30s
      retries: 3
